<!DOCTYPE html>
<html lang="en">
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <title>My Personal Blog with Math</title>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script type="text/javascript">
    MathJax = {
        tex: {
            packages: {'[+]': ['ams', 'newcommand', 'color']}
        }
    };
</script>
        <script type="text/javascript">
        MathJax = {
            tex: {
                macros: {
                    box: ['\\mathord{\\Box}', 0],
                    diamond: ['\\mathord{\\Diamond}', 0]
                }
            }
        };
    </script>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
    </style>
    </head>
    <body>
        <header>
        <h1>Monoidal Categories: Part 2</h1>
        <p>First published on: 2024-06-06</p>
    </header>
    <main>
        <article>
            <p>
                In this post, I try to completely understand the Hilbert Nullstellensatz, which is the very foundation of commutative algebra.
            </p>

            <p>
                Hilbert Nullstellensatz has several versions. Let's start with the weak version. Let \(k\) be an algebraically closed field. If \(I\) is a proper ideal of \(k[x_1,\dots,x_n]\), then it has at least one zero. In other words, \(V(I)\neq\emptyset\). To prove the result, it suffices to consider the case where \(I\) is a maximal ideal, because every ideal is contained in some maximal ideal, according to Zorn's Lemma. 
                So now assume \(m\) is a maximal ideal of \(k[x_1,\dots,x_n]\), then \(k[x_1,\dots,x_n]/m\) is a field and of which \(k\) is a subfield. If we are able to show that the field \(k[x_1,\dots,x_n]/m\) is an algebraic extension of \(k\), then since \(k\) is algebraically closed, we have \(k[x_1,\dots,x_n]/m\cong k\). If so, then there are \(v_1,\dots,v_n\in k\) such that \(\bar{x_i}=v_i\), i.e. \(x_i-v_i\in m\) for 
                all \(i\). This implies that \(m=(x_1-v_1,\dots,x_n-v_n)\), because the ideal on the RHS is maximal. Then we know the point \((v_1,\dots,v_n)\) is a zero of \(m\). 
            </p>

            <p>
                So it is left to show that the field \(k[x_1,\dots,x_n]/m\) is an algebraic extension of \(k\). Actually this can be covered by a so-called Zariski Lemma. The lemma states the following: assume \(L\) is a field which is ring-finite over a subfield \(K\), then \(L\) is actually module-finite over \(K\). Here, ring-finite means that \(L\) is the ring generated by finitely many elements and \(K\), so \(L\) is of the form
                \(K[v_1,\dots,v_n]\), for some elements \(v_1,\dots v_n\in L\); and module finite means that \(L\) is a finite \(K\)-module. Okay, let us start the proof. We prove by induction on \(n\). When \(n=1\), we have to show that \(L=K[v]\) is an algebraic extension of \(K\). Here \(L=K[v]\) implies that there is a surjective ring homorphism \(\varphi\) from \(K[X]\) to \(L\), so \(K[X]/ker(\varphi)\cong L\). We understand that \(ker(\varphi)\) is an ideal of \(K[X]\), 
                and since \(K[X]\) is a PID, there is a polynomial \(F\in K[X]\) such that \(ker(\varphi)=(F)\). We know since \(L\) is a field, \(F\) cannot be zero. Also, we know \(\bar{x}=v\) in \(L\) and \(\bar{F}=0\) in \(L\), which implies that \(F(v)=0\). So \(v\) is actually algebraic over \(K\), therefore \(L\) is module-finite over \(K\).
            </p>

            <p>
                Now, assume \(L=K[v_1,\dots,v_n]\). We have \(L=K(v_1)[v_2,\dots,v_n]\), where \(K(v_1)\) is the smallest field containing \(K\) and \(v_1\). Then by induction hypothesis, \(L\) is module-finite over the field \(K(v_1)\). If \(K(v_1)\) is module-finite over \(K\), then it follows directly that \(L\) is module-finite over \(K\). So in the following we assume that \(K(v_1)\) is not module-finite over \(K\), i.e. \(v_1\) 
                is not algebraic over \(K\), then we understand that \(K(v_1)\) is isomorphic to \(K(X)\). For \(i=2,\dots,n\), \(v_i\) is algebraic over \(K(v_1)\), so it is a zero of a non-zero polynomial with coefficients in \(K(v_1)\). We understand that elements in \(K(v_1)\) is of the form \(\frac{p}{q}\), where \(p,q\) are \(K\)-polynomials values at \(v_1\). So if we multiply all denominators of coefficients in those 
                polynomials of \(v_2,\dots,v_n\) and get \(a\in K[v_1]\), we understand that \(av_2,\dots,av_n\) are integral over \(K[v_1]\). This implies that all elements in \(K[v_1][av_2,\dots,av_n]\) are integral over \(K[v_1]\): we will explain this later. Especially, for every element \(z\) in \(K(v_1)\), there exists positive interger \(N\) such that \(a^{N}z\in K[v_1][av_2,\dots,av_{n}]\) is integral over \(K[v_1]\). We understand that there are 
                infinitely many irreducible polynomials in \(K[X]\), which can be proved in the same way of proving the infinitude of primes: assume \(F_1,\dots,F_n\) are the only irreducible polynomials, then \(F_1\dots F_{n+1}+1\) cannot be divided by any \(F_i\). So we can find a polynomial \(b\in K[v_1]\), such that \(b\) does not divide \(a\). Then \(a^N\frac{1}{b}\) is integral over \(K[v_1]\) for some \(N\), so 
                \((\frac{a^N}{b})^{k}+a_1(\frac{a^N}{b})^{k-1}+\dots+a_k=0\), for \(a_1,\dots,a_k\in K[v_1]\). Multiply enough \(b\), we have \((a^N)^{k}+a_1(a^N b)^{k-1}+\dots+a_{k}b^{k}=0\), so \((a^N)^k=(\dots)b\), which implies that \(b\) divides \(a^{Nk}\), which implies that \(b\) divides \(a\), which is a contradiction. Therefore, \(K(v_1)\) must be algebraic over \(K\), completing the proof.
            </p>

            <p>
                We now explain why in the above proof, why '\(av_2,\dots,av_n\) are integral over \(K[v_1]\)' implies that 'all elements in \(K[v_1][av_2,\dots,av_n]\) are integral over \(K[v_1]\)\(\dots\)'. I can say that it is simply a result of the so-called Nakayama's Lemma, 
                which states the following: let \(M\) be a \(A\)-module which is finitely generated, and \(\varphi\) is \(A\)-linear from \(M\) to \(\alpha M\), where \(\alpha\) is an ideal of \(A\), then there exists \(a_1,\dots,a_n\in \alpha\) such that \(\varphi^{n}+a_1\varphi^{n-1}+\dots+a_n=0\). In our setting, we consider \(M=K[v_1][av_2,\dots,av_n]\), \(A=k[v_1]\) and \(\alpha=(1)\). We already know that \(av_2,.\dots,av_n\) are module-finite over \(K[v_1]\), so \(K[v_1][av_2,\dots,av_n]\) 
                is actually \(k[v_1]\)-finitely-generated. For each \(z\in L\), we understand that there exists a positive integer \(N\) such that \(a^Nz\in k[v_1][av_2,\dots,av_n]\), so define \(\varphi(t)=zt\), which is clearly \(K[v_1]\)-linear. Then we know there is a \(K[v_1]\) polynomial vanishes for \(\varphi\). We set \(t=1\) and get the vanishing polynomial for \(z\). This is a bit tricky I think, because the proof of Nakayama's lemma 
                itself is not that trivial: it uses properties of determinants: actually we will get something like \((\delta_{ij}-a_{ij})x_j=0\), then multiply two sides by the classical adjoint of the matrix \((\delta_{ij}-a_{ij})\), we get \(det(\delta_{ij}-a_{ij})x_k=0\) for all \(k\), which implies that the determinant must be zero. Please note that I am being sloppy here. See details in Atiyah's commutative algebra. 
            </p>

            <p>
                Anyway, I think at the moment we almost fully understand the weak version of Hilbert Nullstellensatz. We may switch to a stronger version, which states that for any ideal \(I\) of \(k[x_1,\dots,x_n]\), we have \(I(V(I))=Rad(I)\). Here \(k\) is algebraically closed. Although it has a name 'stronger', but it is in fact equivalent to the weaker version. We will only prove how it can be implied by the weaker one, since the 
                other direction seems quite trivial.
            </p>

            <p>
                Clearly we have \(Rad(I)\subseteq I(V(I))\), so our task is to prove that \(I(V(I))\subseteq Rad(I)\). Suppose \(G\in I(V(I))\). We know \(I\) is finitely generated by the Hilbert's Basis Theorem, say \(I=(F_1,\dots,F_m)\). We consider the ideal \((F_1,\dots,F_m,x_{n+1}G-1)\) of \(k[x_1,\dots,x_n,x_{n+1}]\). The ideal has no zero for the obvious reason, and by weak version of Hilbert Nullstellensatz, the ideal is in fact the 
                whole ring \(k[x_1,\dots,x_{n+1}]\). So for some polynomials \(A_{i},B\) in \(k[x_1,\dots,x_{n+1}]\), we have \(A_1F_1+\dots+A_mF_m+B(x_{n+1}G-1)=1\). Treat \(k[x_1,\dots,x_{n+1}]\) are a polynomial ring over the ring \(R=k[x_1,\dots,x_n]\), then replacing \(x_{n+1}\) by \(\frac{1}{x_{n+1}}\) can be seen as a ring homomorphism from \(R[x_{n+1}]\) to \(R[\frac{1}{x_{n+1}}]\), and it all happens within the field \(R(x_{n+1})\). Anyway, 
                we get \(A_{1}(x_{n+1};\frac{1}{x_{n+1}})F_1+\dots+A_{m}(x_{n+1};\frac{1}{x_{n+1}})F_m+B(x_{n+1};\frac{1}{x_{n+1}})(\frac{1}{x_{n+1}}G-1)=1\). Multiply enough \(x_{n+1}\), we get \(A'_1F_1+\dots+A'_mF_m+B'(G-x_{n+1})=x_{n+1}^{M}\) for some positive integer \(M\). It is a \(R\)-coefficients polynomial in one variable \(x_{n+1}\), and if we put \(x_{n+1}\) to the value \(G\in R\), we get \(G^M=A'_1(x_{n+1};G)F_1+\dots+A'_{m}(x_{n+1};G)F_{m}\), 
                which implies that \(G^{M}\in I\), so \(G\in Rad(I)\), completing the proof.
            </p>

            <p>
                Wow! Can't believe that all those can be done! Maybe in the end I would mention how to prove weak version from stronger version. If \(I\) is a proper ideal and \(V(I)=\emptyset\), then \(I(V(I))=I(\emptyset)=(1)\), so \(Rad(I)=(1)\) and \(1\in I\), contradicts our assumption that \(I\) is proper. So good! Bye!
            </p>



          
          

            


                
        </article>
        <p><a href="index.html">Back to Home</a></p>
    </main>
        <!-- Your content goes here -->
    </body>
</html>
